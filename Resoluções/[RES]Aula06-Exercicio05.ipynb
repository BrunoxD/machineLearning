{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[SOL]Aula06-Exercicio05.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"aTlpjsyHUTv-","colab_type":"text"},"cell_type":"markdown","source":["# Aula 06 - Exercício 05\n","\n","### Alunos:\n"," - \n"," - "]},{"metadata":{"id":"Lj8Koo4pUWWU","colab_type":"text"},"cell_type":"markdown","source":["## Multilayer Perceptron para classificação do dataset Wine\n","Neste exercício utilizaremos a base de dados Wine, que consiste em 178 exemplos de dimensionalidade 13, separados em 3 classes. Os atributos dessa base de dados não estão normalizados, apresentando intervalos variados de valores.\n","\n","- Carregue a base de dados wine e normalize entre 0 e 1 o valor dos seus atributos"]},{"metadata":{"id":"qgP1cqVAUMQc","colab_type":"code","outputId":"3a9bb7c7-c137-486b-f2e5-96ffcfd8d252","executionInfo":{"status":"ok","timestamp":1554558866369,"user_tz":180,"elapsed":2212,"user":{"displayName":"Felipe Padula Sanches","photoUrl":"https://lh4.googleusercontent.com/-nernBhYcW4o/AAAAAAAAAAI/AAAAAAAANRw/LcF4_Q1FmN8/s64/photo.jpg","userId":"18187017750627346096"}},"colab":{"base_uri":"https://localhost:8080/","height":416}},"cell_type":"code","source":["import numpy as np\n","from sklearn.datasets import load_wine\n","from sklearn.preprocessing import MinMaxScaler\n","\n","x, y = load_wine(return_X_y=True)\n","scaler = MinMaxScaler()\n","print(x)\n","print(np.max(x))\n","print(np.min(x))\n","scaler.fit(x)\n","x = scaler.transform(x)\n","print(x)\n","print(np.max(x))\n","print(np.min(x))\n","print(y)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["[[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n"," [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n"," [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n"," ...\n"," [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n"," [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n"," [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n","1680.0\n","0.13\n","[[0.84210526 0.1916996  0.57219251 ... 0.45528455 0.97069597 0.56134094]\n"," [0.57105263 0.2055336  0.4171123  ... 0.46341463 0.78021978 0.55064194]\n"," [0.56052632 0.3201581  0.70053476 ... 0.44715447 0.6959707  0.64693295]\n"," ...\n"," [0.58947368 0.69960474 0.48128342 ... 0.08943089 0.10622711 0.39728959]\n"," [0.56315789 0.36561265 0.54010695 ... 0.09756098 0.12820513 0.40085592]\n"," [0.81578947 0.66403162 0.73796791 ... 0.10569106 0.12087912 0.20114123]]\n","1.0\n","0.0\n","[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"],"name":"stdout"}]},{"metadata":{"id":"YxuLjxtg0uZ2","colab_type":"text"},"cell_type":"markdown","source":["---\n","- Agora divida a base em conjunto de teste e treino. Utilize 20% da base para teste e 80% para treino."]},{"metadata":{"id":"b8T1WrYHVs80","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.20,random_state=1, stratify=y)\n","# x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.20,random_state=1)\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vv0RbhEr8ZIC","colab_type":"text"},"cell_type":"markdown","source":["### Comentário\n","Embora eu não tenha pedido no exercício, é interessante utilizar o parâmetro stratify. O classificador apresenta um resultado muito mais próximo do esperado se utilizarmos um conjunto estratificado (proporção das classes do conjunto original se mantém nos conjuntos de treino e teste). \n","\n","Lembro que algumas pessoas em sala reportaram uma acurácia de 100% no conjunto de teste. O que pode ter acontecido é que uma classe mais \"fácil\" de ser classificada foi favorecida na hora de dividir os conjuntos, levando o classificador a errar menos."]},{"metadata":{"id":"YpZ85fjn08Hp","colab_type":"text"},"cell_type":"markdown","source":["---\n","- Treine 3 classificadores MLP (com `solver='sgd'`), variando o número de neurônios na camada escondida. Reporte o score dos classificadores nos conjuntos de treino e teste."]},{"metadata":{"id":"6B5F6mAazFO9","colab_type":"code","outputId":"3508b88c-f409-4428-fb10-11945d9bfb31","executionInfo":{"status":"ok","timestamp":1554560346900,"user_tz":180,"elapsed":694,"user":{"displayName":"Felipe Padula Sanches","photoUrl":"https://lh4.googleusercontent.com/-nernBhYcW4o/AAAAAAAAAAI/AAAAAAAANRw/LcF4_Q1FmN8/s64/photo.jpg","userId":"18187017750627346096"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"cell_type":"code","source":["from sklearn.neural_network import MLPClassifier\n","\n","sizes = [2, 5, 10]\n","mlps = []\n","for i in range(0, 3):\n","  mlps.append(MLPClassifier(hidden_layer_sizes=(sizes[i],), max_iter=200,\n","                      solver='sgd', tol=1e-3, random_state=1,\n","                      learning_rate_init=.1))\n","\n","  mlps[i].fit(x_train, y_train)\n","  print(\"Training set score: %f\" % mlps[i].score(x_train, y_train))\n","  print(\"Test set score: %f\" % mlps[i].score(x_test, y_test))\n","  \n","best = 1\n","worst = 0"],"execution_count":44,"outputs":[{"output_type":"stream","text":["Training set score: 0.401408\n","Test set score: 0.388889\n","Training set score: 1.000000\n","Test set score: 0.972222\n","Training set score: 0.992958\n","Test set score: 0.972222\n"],"name":"stdout"}]},{"metadata":{"id":"PfX6WYjh13GS","colab_type":"text"},"cell_type":"markdown","source":["---\n","- Selecione uma amostra de tamanho 10 do conjunto de testes. Selecione o classificador que apresentou maior acurácia no conjunto de testes e calcule, para cada elemento da amostra, a classe esperada, a classe obtida e a probabilidade estimada de cada classe"]},{"metadata":{"id":"V98MdpUaJPuH","colab_type":"code","outputId":"915b62f2-f513-40f0-9017-c3f04d70d445","executionInfo":{"status":"ok","timestamp":1554560350507,"user_tz":180,"elapsed":830,"user":{"displayName":"Felipe Padula Sanches","photoUrl":"https://lh4.googleusercontent.com/-nernBhYcW4o/AAAAAAAAAAI/AAAAAAAANRw/LcF4_Q1FmN8/s64/photo.jpg","userId":"18187017750627346096"}},"colab":{"base_uri":"https://localhost:8080/","height":538}},"cell_type":"code","source":["samples = x_test[10:20]\n","samples_t = y_test[10:20]\n","\n","pred_proba = mlps[best].predict_proba(samples)\n","pred = mlps[best].predict(samples)\n","\n","i = 0\n","for prob in pred_proba:\n","  print(\"Amostra %d:\" % i)\n","  print(\"Esperado %s, obtido %s\" % (samples_t[i], pred[i]))\n","  print(prob.round(2))\n","  i += 1\n"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Amostra 0:\n","Esperado 0, obtido 0\n","[1. 0. 0.]\n","Amostra 1:\n","Esperado 1, obtido 1\n","[0.32 0.66 0.02]\n","Amostra 2:\n","Esperado 1, obtido 1\n","[0.02 0.97 0.01]\n","Amostra 3:\n","Esperado 2, obtido 2\n","[0.01 0.06 0.93]\n","Amostra 4:\n","Esperado 1, obtido 1\n","[0. 1. 0.]\n","Amostra 5:\n","Esperado 1, obtido 1\n","[0.01 0.99 0.  ]\n","Amostra 6:\n","Esperado 1, obtido 1\n","[0. 1. 0.]\n","Amostra 7:\n","Esperado 0, obtido 0\n","[1. 0. 0.]\n","Amostra 8:\n","Esperado 0, obtido 0\n","[1. 0. 0.]\n","Amostra 9:\n","Esperado 0, obtido 0\n","[1. 0. 0.]\n"],"name":"stdout"}]},{"metadata":{"id":"03NDi1Re23W5","colab_type":"text"},"cell_type":"markdown","source":["---\n","- Agora sobre a mesma amostra escolhida anteriormente, selecione o classificador que apresentou menor acurácia no conjunto de testes e calcule, para cada elemento da amostra, a classe esperada, a classe obtida e a probabilidade esperada de cada classe."]},{"metadata":{"id":"F5OBeWOR3Kdr","colab_type":"code","outputId":"215c7741-8b15-42c8-8253-95373dd4bb2c","executionInfo":{"status":"ok","timestamp":1554560354469,"user_tz":180,"elapsed":742,"user":{"displayName":"Felipe Padula Sanches","photoUrl":"https://lh4.googleusercontent.com/-nernBhYcW4o/AAAAAAAAAAI/AAAAAAAANRw/LcF4_Q1FmN8/s64/photo.jpg","userId":"18187017750627346096"}},"colab":{"base_uri":"https://localhost:8080/","height":538}},"cell_type":"code","source":["pred_proba = mlps[worst].predict_proba(samples)\n","pred = mlps[worst].predict(samples)\n","\n","i = 0\n","for prob in pred_proba:\n","  print(\"Amostra %d:\" % i)\n","  print(\"Esperado %s, obtido %s\" % (samples_t[i], pred[i]))\n","  print(prob.round(2))\n","  i += 1"],"execution_count":46,"outputs":[{"output_type":"stream","text":["Amostra 0:\n","Esperado 0, obtido 1\n","[0.31 0.45 0.24]\n","Amostra 1:\n","Esperado 1, obtido 1\n","[0.31 0.45 0.24]\n","Amostra 2:\n","Esperado 1, obtido 1\n","[0.31 0.45 0.24]\n","Amostra 3:\n","Esperado 2, obtido 1\n","[0.31 0.45 0.24]\n","Amostra 4:\n","Esperado 1, obtido 1\n","[0.31 0.45 0.24]\n","Amostra 5:\n","Esperado 1, obtido 1\n","[0.31 0.45 0.24]\n","Amostra 6:\n","Esperado 1, obtido 1\n","[0.31 0.45 0.24]\n","Amostra 7:\n","Esperado 0, obtido 1\n","[0.31 0.45 0.24]\n","Amostra 8:\n","Esperado 0, obtido 1\n","[0.31 0.45 0.24]\n","Amostra 9:\n","Esperado 0, obtido 1\n","[0.31 0.45 0.24]\n"],"name":"stdout"}]},{"metadata":{"id":"aZF6M90l3dfd","colab_type":"text"},"cell_type":"markdown","source":["\n","\n","---\n","\n","- Faça uma análise das probabilidades calculadas por cada classificador nos exemplos corretos e relacione-as com a 'qualidade' dos mesmos."]},{"metadata":{"id":"yCVPzVVJ7wql","colab_type":"text"},"cell_type":"markdown","source":["O classificador que apresenta 'qualidade' mais alta apresenta maior probabilidade nas classes esperadas, quando comparado ao outro. Por exemplo, embora a amostra 2 tenha sido classificada corretamente nos dois classificadores, o primeiro classificador apresentou uma confiança muito maior que o segundo."]},{"metadata":{"id":"N1jAIHbtU2hV","colab_type":"text"},"cell_type":"markdown","source":["---\n","- Calcule, usando 10-fold cross-validation, a acurácia média da melhor configuração de classificador que você utilizou e seu desvio padrão"]},{"metadata":{"id":"9c8d3GMTU41W","colab_type":"code","outputId":"cca332af-562f-48be-d086-b62b38924b2e","executionInfo":{"status":"ok","timestamp":1554560406857,"user_tz":180,"elapsed":1005,"user":{"displayName":"Felipe Padula Sanches","photoUrl":"https://lh4.googleusercontent.com/-nernBhYcW4o/AAAAAAAAAAI/AAAAAAAANRw/LcF4_Q1FmN8/s64/photo.jpg","userId":"18187017750627346096"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"cell_type":"code","source":["from sklearn.model_selection import StratifiedKFold\n","scores = []\n","skf = StratifiedKFold(n_splits=10)\n","for train_index, test_index in skf.split(x, y):\n","  x_train, x_test = x[train_index], x[test_index]\n","  y_train, y_test = y[train_index], y[test_index]\n","  mlp = MLPClassifier(hidden_layer_sizes=(5,), max_iter=200,\n","                      solver='sgd', tol=1e-3, random_state=1,\n","                      learning_rate_init=.1)\n","\n","  mlp.fit(x_train, y_train)  \n","  scores.append(mlp.score(x_test, y_test))\n","print(scores)\n","scores = np.asarray(scores)\n","print(np.mean(scores))\n","print(np.std(scores))"],"execution_count":48,"outputs":[{"output_type":"stream","text":["[1.0, 0.9444444444444444, 1.0, 0.9444444444444444, 0.9444444444444444, 1.0, 1.0, 1.0, 1.0, 1.0]\n","0.9833333333333334\n","0.02545875386086579\n"],"name":"stdout"}]}]}