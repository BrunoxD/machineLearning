{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula06-Exercicio05.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "aTlpjsyHUTv-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Aula 06 - Exercício 05\n",
        "\n",
        "### Alunos:\n",
        " - Bruno Gomes Coelho       - 9791160\n",
        " - Bruno Mendes da Costa - 9779433\n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "aXeXCTX0YzEp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ]
    },
    {
      "metadata": {
        "id": "_9ilk-m9YxTm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lj8Koo4pUWWU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Multilayer Perceptron para classificação do dataset Wine\n",
        "Neste exercício utilizaremos a base de dados Wine, que consiste em 178 exemplos de dimensionalidade 13, separados em 3 classes. Os atributos dessa base de dados não estão normalizados, apresentando intervalos variados de valores.\n",
        "\n",
        "- Carregue a base de dados wine e normalize entre 0 e 1 o valor dos seus atributos"
      ]
    },
    {
      "metadata": {
        "id": "qgP1cqVAUMQc",
        "colab_type": "code",
        "outputId": "b42b1704-3e03-40d3-8c86-f4f6ab26ffb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "cell_type": "code",
      "source": [
        "# Carregando o dataset\n",
        "data = load_wine()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
              "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
              "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
              "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
              "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
              "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
              "\n",
              "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
              "0        3.06                  0.28             2.29             5.64  1.04   \n",
              "1        2.76                  0.26             1.28             4.38  1.05   \n",
              "2        3.24                  0.30             2.81             5.68  1.03   \n",
              "3        3.49                  0.24             2.18             7.80  0.86   \n",
              "4        2.69                  0.39             1.82             4.32  1.04   \n",
              "\n",
              "   od280/od315_of_diluted_wines  proline  \n",
              "0                          3.92   1065.0  \n",
              "1                          3.40   1050.0  \n",
              "2                          3.17   1185.0  \n",
              "3                          3.45   1480.0  \n",
              "4                          2.93    735.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "n6efNr-ZZXiB",
        "colab_type": "code",
        "outputId": "651fc14f-3e56-4062-e3b8-6c00b470985d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "cell_type": "code",
      "source": [
        "# Normalizando os dados\n",
        "scaler = MinMaxScaler()\n",
        "df.loc[:,:] = scaler.fit_transform(df)\n",
        "df['target'] = data.target\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.842105</td>\n",
              "      <td>0.191700</td>\n",
              "      <td>0.572193</td>\n",
              "      <td>0.257732</td>\n",
              "      <td>0.619565</td>\n",
              "      <td>0.627586</td>\n",
              "      <td>0.573840</td>\n",
              "      <td>0.283019</td>\n",
              "      <td>0.593060</td>\n",
              "      <td>0.372014</td>\n",
              "      <td>0.455285</td>\n",
              "      <td>0.970696</td>\n",
              "      <td>0.561341</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.571053</td>\n",
              "      <td>0.205534</td>\n",
              "      <td>0.417112</td>\n",
              "      <td>0.030928</td>\n",
              "      <td>0.326087</td>\n",
              "      <td>0.575862</td>\n",
              "      <td>0.510549</td>\n",
              "      <td>0.245283</td>\n",
              "      <td>0.274448</td>\n",
              "      <td>0.264505</td>\n",
              "      <td>0.463415</td>\n",
              "      <td>0.780220</td>\n",
              "      <td>0.550642</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.560526</td>\n",
              "      <td>0.320158</td>\n",
              "      <td>0.700535</td>\n",
              "      <td>0.412371</td>\n",
              "      <td>0.336957</td>\n",
              "      <td>0.627586</td>\n",
              "      <td>0.611814</td>\n",
              "      <td>0.320755</td>\n",
              "      <td>0.757098</td>\n",
              "      <td>0.375427</td>\n",
              "      <td>0.447154</td>\n",
              "      <td>0.695971</td>\n",
              "      <td>0.646933</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.878947</td>\n",
              "      <td>0.239130</td>\n",
              "      <td>0.609626</td>\n",
              "      <td>0.319588</td>\n",
              "      <td>0.467391</td>\n",
              "      <td>0.989655</td>\n",
              "      <td>0.664557</td>\n",
              "      <td>0.207547</td>\n",
              "      <td>0.558360</td>\n",
              "      <td>0.556314</td>\n",
              "      <td>0.308943</td>\n",
              "      <td>0.798535</td>\n",
              "      <td>0.857347</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.581579</td>\n",
              "      <td>0.365613</td>\n",
              "      <td>0.807487</td>\n",
              "      <td>0.536082</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.627586</td>\n",
              "      <td>0.495781</td>\n",
              "      <td>0.490566</td>\n",
              "      <td>0.444795</td>\n",
              "      <td>0.259386</td>\n",
              "      <td>0.455285</td>\n",
              "      <td>0.608059</td>\n",
              "      <td>0.325963</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    alcohol  malic_acid       ash  alcalinity_of_ash  magnesium  \\\n",
              "0  0.842105    0.191700  0.572193           0.257732   0.619565   \n",
              "1  0.571053    0.205534  0.417112           0.030928   0.326087   \n",
              "2  0.560526    0.320158  0.700535           0.412371   0.336957   \n",
              "3  0.878947    0.239130  0.609626           0.319588   0.467391   \n",
              "4  0.581579    0.365613  0.807487           0.536082   0.521739   \n",
              "\n",
              "   total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
              "0       0.627586    0.573840              0.283019         0.593060   \n",
              "1       0.575862    0.510549              0.245283         0.274448   \n",
              "2       0.627586    0.611814              0.320755         0.757098   \n",
              "3       0.989655    0.664557              0.207547         0.558360   \n",
              "4       0.627586    0.495781              0.490566         0.444795   \n",
              "\n",
              "   color_intensity       hue  od280/od315_of_diluted_wines   proline  target  \n",
              "0         0.372014  0.455285                      0.970696  0.561341       0  \n",
              "1         0.264505  0.463415                      0.780220  0.550642       0  \n",
              "2         0.375427  0.447154                      0.695971  0.646933       0  \n",
              "3         0.556314  0.308943                      0.798535  0.857347       0  \n",
              "4         0.259386  0.455285                      0.608059  0.325963       0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "YxuLjxtg0uZ2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "- Agora divida a base em conjunto de teste e treino. Utilize 20% da base para teste e 80% para treino."
      ]
    },
    {
      "metadata": {
        "id": "b8T1WrYHVs80",
        "colab_type": "code",
        "outputId": "af016660-5cdb-4098-dc72-c60041cdf4c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "# Separando em treino e teste\n",
        "x_train, x_test, y_train, y_test = train_test_split(df.drop(columns=['target']), df['target'], train_size=0.8, random_state=9)\n",
        "print([len(k) for k in [x_train, x_test, y_train, y_test]])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[142, 36, 142, 36]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "YpZ85fjn08Hp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "- Treine 3 classificadores MLP (com `solver='sgd'`), variando o número de neurônios na camada escondida. Reporte o score dos classificadores nos conjuntos de treino e teste."
      ]
    },
    {
      "metadata": {
        "id": "6B5F6mAazFO9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Esconde os Warnings\n",
        "%%capture \n",
        "# Treinando 3 classificadores\n",
        "models = []\n",
        "strings = []\n",
        "for i in [50, 100, 125]:\n",
        "  model = MLPClassifier(solver='sgd', hidden_layer_sizes=(i,), random_state=9)\n",
        "  model.fit(x_train.values, y_train)\n",
        "  y_pred = model.predict(x_test)\n",
        "  strings.append(f\"Modelo com {i} neurônios da camada escondida: {accuracy_score(y_test, y_pred)}\")  \n",
        "  models.append(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9muZaOVQreU7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "51910050-ac2e-4a55-a0be-2f067b2c9c6e"
      },
      "cell_type": "code",
      "source": [
        "print(*strings, sep='\\n')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Modelo com 50 neurônios da camada escondida: 0.5\n",
            "Modelo com 100 neurônios da camada escondida: 0.8888888888888888\n",
            "Modelo com 125 neurônios da camada escondida: 0.9722222222222222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TwyuD1fvkEIm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_results(model):\n",
        "  y_pred = model.predict(x_test.iloc[:10])\n",
        "  print(f\"Modelo com {model.hidden_layer_sizes[0]} neurônios da camada escondida: \", accuracy_score(y_test.iloc[:10], y_pred))\n",
        "  y_proba = model.predict_proba(x_test.iloc[:10])\n",
        "\n",
        "  display = pd.DataFrame()\n",
        "  for a, b, c in zip(y_test.iloc[:10], y_pred, y_proba):  \n",
        "    display = display.append([[a, b, *c]])\n",
        "  display.columns = [\"Esperada\", \"Predita\", \"Prob 0\", \"Prob 1\", \"Prob 2\"]\n",
        "  display.reset_index(drop=True, inplace=True)\n",
        "  return display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PfX6WYjh13GS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "- Selecione uma amostra de tamanho 10 do conjunto de testes. Selecione o classificador que apresentou maior acurácia no conjunto de testes e calcule, para cada elemento da amostra, a classe esperada, a classe obtida e a probabilidade estimada de cada classe"
      ]
    },
    {
      "metadata": {
        "id": "V98MdpUaJPuH",
        "colab_type": "code",
        "outputId": "87a2a98c-708f-404d-afb9-af6dbc288c58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "cell_type": "code",
      "source": [
        "# Como o último modelo apresentou o melhor resultado, não precisamos treinar o modelo novamente.\n",
        "model_results(models[-1]).head(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Modelo com 125 neurônios da camada escondida:  1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Esperada</th>\n",
              "      <th>Predita</th>\n",
              "      <th>Prob 0</th>\n",
              "      <th>Prob 1</th>\n",
              "      <th>Prob 2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.479652</td>\n",
              "      <td>0.319947</td>\n",
              "      <td>0.200401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.408419</td>\n",
              "      <td>0.393057</td>\n",
              "      <td>0.198524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.433637</td>\n",
              "      <td>0.354001</td>\n",
              "      <td>0.212362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.291180</td>\n",
              "      <td>0.261248</td>\n",
              "      <td>0.447572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.467067</td>\n",
              "      <td>0.324732</td>\n",
              "      <td>0.208201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.463016</td>\n",
              "      <td>0.355395</td>\n",
              "      <td>0.181590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.315393</td>\n",
              "      <td>0.309545</td>\n",
              "      <td>0.375062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.271880</td>\n",
              "      <td>0.280615</td>\n",
              "      <td>0.447505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.261214</td>\n",
              "      <td>0.338597</td>\n",
              "      <td>0.400189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.304165</td>\n",
              "      <td>0.471125</td>\n",
              "      <td>0.224710</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Esperada  Predita    Prob 0    Prob 1    Prob 2\n",
              "0         0        0  0.479652  0.319947  0.200401\n",
              "1         0        0  0.408419  0.393057  0.198524\n",
              "2         0        0  0.433637  0.354001  0.212362\n",
              "3         2        2  0.291180  0.261248  0.447572\n",
              "4         0        0  0.467067  0.324732  0.208201\n",
              "5         0        0  0.463016  0.355395  0.181590\n",
              "6         2        2  0.315393  0.309545  0.375062\n",
              "7         2        2  0.271880  0.280615  0.447505\n",
              "8         2        2  0.261214  0.338597  0.400189\n",
              "9         1        1  0.304165  0.471125  0.224710"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "03NDi1Re23W5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "- Agora sobre a mesma amostra escolhida anteriormente, selecione o classificador que apresentou menor acurácia no conjunto de testes e calcule, para cada elemento da amostra, a classe esperada, a classe obtida e a probabilidade esperada de cada classe."
      ]
    },
    {
      "metadata": {
        "id": "F5OBeWOR3Kdr",
        "colab_type": "code",
        "outputId": "12004df8-473d-4ceb-959e-37784d28106a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "cell_type": "code",
      "source": [
        "# Apresentand os resultados para o primeiro modelo\n",
        "model_results(models[0]).head(10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Modelo com 50 neurônios da camada escondida:  0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Esperada</th>\n",
              "      <th>Predita</th>\n",
              "      <th>Prob 0</th>\n",
              "      <th>Prob 1</th>\n",
              "      <th>Prob 2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.373275</td>\n",
              "      <td>0.441266</td>\n",
              "      <td>0.185459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.401803</td>\n",
              "      <td>0.402696</td>\n",
              "      <td>0.195500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.350508</td>\n",
              "      <td>0.443332</td>\n",
              "      <td>0.206160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.218574</td>\n",
              "      <td>0.335098</td>\n",
              "      <td>0.446328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.382174</td>\n",
              "      <td>0.429957</td>\n",
              "      <td>0.187868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.413542</td>\n",
              "      <td>0.407239</td>\n",
              "      <td>0.179219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.233037</td>\n",
              "      <td>0.402447</td>\n",
              "      <td>0.364516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.212127</td>\n",
              "      <td>0.333029</td>\n",
              "      <td>0.454843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.208487</td>\n",
              "      <td>0.334771</td>\n",
              "      <td>0.456742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.341953</td>\n",
              "      <td>0.401121</td>\n",
              "      <td>0.256926</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Esperada  Predita    Prob 0    Prob 1    Prob 2\n",
              "0         0        1  0.373275  0.441266  0.185459\n",
              "1         0        1  0.401803  0.402696  0.195500\n",
              "2         0        1  0.350508  0.443332  0.206160\n",
              "3         2        2  0.218574  0.335098  0.446328\n",
              "4         0        1  0.382174  0.429957  0.187868\n",
              "5         0        0  0.413542  0.407239  0.179219\n",
              "6         2        1  0.233037  0.402447  0.364516\n",
              "7         2        2  0.212127  0.333029  0.454843\n",
              "8         2        2  0.208487  0.334771  0.456742\n",
              "9         1        1  0.341953  0.401121  0.256926"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "aZF6M90l3dfd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "- Faça uma análise das probabilidades calculadas por cada classificador nos exemplos corretos e relacione-as com a 'qualidade' dos mesmos."
      ]
    },
    {
      "metadata": {
        "id": "yCVPzVVJ7wql",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Podemos observar no primeiro classificador que para todos os casos corretos, o classificador obteve pelo menos 37% de certeza sobre a classe correta e em relação as classes incorretas houve no máximo 39% de certeza.\n",
        "\n",
        "No segundo classificador quando a classe predita foi correta, houve no mínimo 40% de certeza, no entanto, a diferença entre as probabilidades de forma geral se mostraram muito próximas, ou seja, houve dúvida entre quais classes classificar que acabou levando o modelo a algumas vezes classificar de forma incorreta."
      ]
    },
    {
      "metadata": {
        "id": "BkCZAX_VUdDD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "- Calcule, usando 10-fold cross-validation, a acurácia média da melhor configuração de classificador que você utilizou e seu desvio padrão"
      ]
    },
    {
      "metadata": {
        "id": "8lJCpQ8FU8ca",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Esconde os Warnings\n",
        "%%capture \n",
        "kfold = StratifiedKFold(n_splits=10, random_state=9)\n",
        "acc = []\n",
        "for train_index, test_index in kfold.split(x_train, y_train):\n",
        "  model = MLPClassifier(solver=\"sgd\", hidden_layer_sizes=(125, ), random_state=9)\n",
        "  model.fit(x_train.iloc[train_index], y_train.iloc[train_index])  \n",
        "  y_pred = model.predict(x_train.iloc[test_index])\n",
        "  acc.append(accuracy_score(y_train.iloc[test_index], y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nGy0X0r8pBw_",
        "colab_type": "code",
        "outputId": "1057c832-e301-446c-b347-fde5e28a90a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "print(f\"Acurácia Média: {np.mean(acc)}\\nDesvio Padrão: {np.std(acc)}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia Média: 0.8876190476190476\n",
            "Desvio Padrão: 0.05631141142512185\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}